{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995cc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c96fd1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.1\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60d866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, precision_score,\n",
    "                             recall_score, roc_auc_score)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (AutoConfig, AutoModel, AutoModelForSequenceClassification,\n",
    "                          AutoTokenizer, BertTokenizer, Trainer,\n",
    "                          TrainingArguments)\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer\n",
    "from transformers import Trainer , TrainingArguments\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import resample\n",
    "import logging\n",
    "import torch\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d26362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded from path ../data/subtask1/split70.json\n",
      "data loaded from path ../data/subtask1/split10.json\n"
     ]
    }
   ],
   "source": [
    "train_data = load_json('../data/subtask1/split70.json')\n",
    "dev_data = load_json('../data/subtask1/split10.json')\n",
    "\n",
    "def normalize_data(items):\n",
    "    normalized_data = []\n",
    "    text_lists = []\n",
    "    label_list = []\n",
    "    for item in items:\n",
    "        sentence_id = item['global_sentence_id']\n",
    "        sentence = []\n",
    "        labels = []\n",
    "        for token_info in item['tokens']:\n",
    "            word = token_info['token']\n",
    "            tv = token_info['tags'][0]\n",
    "            label = tv['value']\n",
    "            sentence.append(word)\n",
    "            labels.append(label)\n",
    "        #sentence = ' '.join(sentence)\n",
    "        #labels = ' '.join(labels)\n",
    "        text_lists.append(sentence)\n",
    "        label_list.append(labels)\n",
    "    return text_lists, label_list\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "text_train, labels_train = normalize_data(train_data)\n",
    "text_dev, labels_dev = normalize_data(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa994467",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = list(set([label for sublist in labels_train for label in sublist]))\n",
    "label_map = { v:index for index, v in enumerate(all_labels)}\n",
    "inv_label_map = {i: label for i, label in enumerate(all_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa89acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import NERDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fd59863",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "task_name = 'tokenclassification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca48a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(\n",
    "    texts=text_train,\n",
    "    tags=labels_train,\n",
    "    label_list=all_labels,\n",
    "    model_name=model_name,\n",
    "    max_length=512\n",
    "    )\n",
    "\n",
    "dev_dataset = NERDataset(\n",
    "    texts=text_dev,\n",
    "    tags=labels_dev,\n",
    "    label_list=all_labels,\n",
    "    model_name=model_name,\n",
    "    max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6e1f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([390900, 768]), torch.Size([390900]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore_path = './'\n",
    "datastore_keys = torch.from_numpy(load_npy(datastore_path + 'datastore_keys.npy'))\n",
    "datastore_values = torch.from_numpy(load_npy(datastore_path + 'datastore_values.npy'))\n",
    "\n",
    "datastore_keys.shape, datastore_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f2bb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore_values.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ada418",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = torch.bincount(datastore_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0657d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([253952,     53,    309,    899,    141,   2922,   3586,    412,  10590,\n",
       "          7999,   1365,   3717,   4107,    560,   4714,    997,    172,   1291,\n",
       "            96,    139,     61,    747,  16337,      3,   1850,   8052,    310,\n",
       "           350,  10705,   4519,    346,     92,      4,     43,    368,    250,\n",
       "          2739,     15,      6,   5758,    974,  39350])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a08f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i in range(42)]\n",
    "\n",
    "# Define the maximum number of samples for each index\n",
    "max_samples = 500  # or any other number\n",
    "\n",
    "# Create a mask for these indices\n",
    "mask = torch.zeros(datastore_values.size(), dtype=torch.bool)\n",
    "for index in indices:\n",
    "    # Create a mask for the current index\n",
    "    index_mask = (datastore_values == index)\n",
    "\n",
    "    # Calculate the number of samples to remove from the current index\n",
    "    reduction_amount = max(0, index_mask.sum() - max_samples)\n",
    "\n",
    "    # If reduction_amount is more than the total number of samples for the current index, set it to the total number\n",
    "    reduction_amount = min(reduction_amount, index_mask.sum())\n",
    "\n",
    "    # Create a random mask for the current index\n",
    "    random_mask = torch.rand(datastore_values.size()) > (1 - reduction_amount / index_mask.sum())\n",
    "\n",
    "    # Combine the masks\n",
    "    mask |= index_mask & random_mask\n",
    "\n",
    "# Apply the mask to the tensor\n",
    "new_datastore_values = datastore_values[~mask]\n",
    "new_datastore_keys = datastore_keys[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "542ecb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14732]), torch.Size([14732, 768]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_datastore_values.shape, new_datastore_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70804cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_datastore_values.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd1eaa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = torch.bincount(new_datastore_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57438f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([486,  53, 309, 492, 141, 556, 513, 412, 525, 511, 488, 476, 499, 499,\n",
       "        481, 502, 172, 475,  96, 139,  61, 488, 534,   3, 477, 548, 310, 350,\n",
       "        498, 498, 346,  92,   4,  43, 368, 250, 502,  15,   6, 509, 500, 505])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fa95c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([57547, 768]), torch.Size([57547]), torch.Size([57547, 42]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = torch.from_numpy(load_npy(datastore_path + 'test_embeddings.npy'))\n",
    "labels = torch.from_numpy(load_npy(datastore_path + 'test_labels.npy'))\n",
    "logits = torch.from_numpy(load_npy(datastore_path + 'test_logits.npy'))\n",
    "\n",
    "embeddings.shape, labels.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4965b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 57547, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3776261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 57547, 768]),\n",
       " torch.Size([1, 57547]),\n",
       " torch.Size([1, 57547, 42]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embeddings.unsqueeze(0)\n",
    "labels = labels.unsqueeze(0)\n",
    "logits = logits.unsqueeze(0)\n",
    "\n",
    "embeddings.shape, labels.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29257d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 57547])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = torch.argmax(logits, axis=-1)\n",
    "predicted_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fd5287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     37983\n",
      "           1       0.33      0.67      0.44         3\n",
      "           2       0.81      0.88      0.84        33\n",
      "           3       0.84      0.88      0.86       133\n",
      "           4       1.00      1.00      1.00        16\n",
      "           5       0.76      0.77      0.77       414\n",
      "           6       0.80      0.87      0.83       508\n",
      "           7       0.75      0.70      0.72        80\n",
      "           8       0.95      0.96      0.96      1488\n",
      "           9       0.97      0.94      0.95      1170\n",
      "          10       0.93      0.96      0.95       204\n",
      "          11       0.96      0.96      0.96       514\n",
      "          12       0.78      0.78      0.78       589\n",
      "          13       0.81      0.85      0.83        86\n",
      "          14       0.99      0.98      0.98       595\n",
      "          15       0.86      0.89      0.88       130\n",
      "          16       0.90      0.86      0.88        22\n",
      "          17       0.88      0.89      0.88       170\n",
      "          18       0.83      0.67      0.74        15\n",
      "          19       0.82      0.88      0.85        16\n",
      "          20       0.57      0.50      0.53         8\n",
      "          21       0.86      0.84      0.85       108\n",
      "          22       0.96      0.96      0.96      2272\n",
      "          23       0.00      0.00      0.00         4\n",
      "          24       0.89      0.84      0.87       282\n",
      "          25       0.95      0.96      0.96      1116\n",
      "          26       0.72      1.00      0.84        36\n",
      "          27       0.96      0.90      0.93        30\n",
      "          28       0.96      0.96      0.96      1592\n",
      "          29       0.97      0.97      0.97       611\n",
      "          30       0.95      0.94      0.95        66\n",
      "          31       1.00      0.92      0.96        12\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.50      0.67      0.57         3\n",
      "          34       0.84      0.91      0.88        47\n",
      "          35       0.84      0.94      0.89        17\n",
      "          36       0.95      0.95      0.95       445\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.96      0.97      0.97       801\n",
      "          40       0.85      0.90      0.87       135\n",
      "          41       0.99      0.99      0.99      5788\n",
      "\n",
      "    accuracy                           0.97     57547\n",
      "   macro avg       0.78      0.80      0.79     57547\n",
      "weighted avg       0.97      0.97      0.97     57547\n",
      "\n",
      "Macro F1-score: 78.52\n",
      "Micro F1-score: 97.30\n",
      "Weighted F1-score: 97.30\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d0fe8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(logits, embeddings, datastore_keys, datastore_values, num_labels,K, lambda_, link_temperature=1.0):\n",
    "    # cosine similarity\n",
    "    knn_feats = datastore_keys.squeeze(0).transpose(0, 1) # [feature_size=768, datastore_size]\n",
    "    embeddings = embeddings.view(-1, embeddings.shape[-1])  # [sentences, feature_size=768]\n",
    "    sim = torch.mm(embeddings, knn_feats) # [sentences, datastore_size]\n",
    "\n",
    "    sentences = embeddings.shape[0]\n",
    "    datastore_size = knn_feats.shape[1]\n",
    "\n",
    "    norm_1 = (knn_feats ** 2).sum(dim=0, keepdim=True).sqrt() # [1, datastore_size]\n",
    "    norm_2 = (embeddings ** 2).sum(dim=1, keepdim=True).sqrt() # [sentences, 1]\n",
    "    scores = (sim / (norm_1 + 1e-10) / (norm_2 + 1e-10)).view(1, sentences, -1) # [1, sentences, datastore_size]\n",
    "    knn_labels = datastore_values.view(1, 1, datastore_size).expand(1, sentences, datastore_size) # [1, sentences, datastore_size]\n",
    "\n",
    "    # select scores and labels of the top k only\n",
    "    topk_scores, topk_idxs = torch.topk(scores, dim=-1, k=K)  # [1, sentences, topk]\n",
    "    scores = topk_scores\n",
    "    knn_labels = knn_labels.gather(dim=-1, index=topk_idxs)  # [[1, sentences, topk]\n",
    "\n",
    "    # transform scores to softmax probabilities\n",
    "    sim_probs = torch.softmax(scores / link_temperature, dim=-1) # [[1, sentences, topk]\n",
    "\n",
    "    # 1. create zero tensor for probabilites as placeholder\n",
    "    knn_probabilities = torch.zeros_like(sim_probs[:, :, 0]).unsqueeze(-1).repeat([1, 1, num_labels])  # [1, sentences, num_labels]\n",
    "    # for each row (dim=2)\n",
    "    # sum the probabilities from sim softmax probabilities (src=sim_probs) grouped by class (index=knn_labels)\n",
    "    knn_probabilities = knn_probabilities.scatter_add(dim=2, index=knn_labels, src=sim_probs) # [1, sentences, num_labels]\n",
    "\n",
    "    # interpolate between logits and knn_probabilites\n",
    "    probabilities = lambda_*logits + (1-lambda_)*knn_probabilities\n",
    "\n",
    "    # argmax to get most likely label\n",
    "    argmax_labels = torch.argmax(probabilities, 2, keepdim=False)\n",
    "\n",
    "    # return predicted labels\n",
    "    return argmax_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43cedbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 500, 42]), torch.Size([1, 500, 768]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlogits, tembeddings, tlabels = logits[:,:500:], embeddings[:,:500,:], labels[:,:500]\n",
    "\n",
    "tlogits.shape, tembeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7290a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(y_true, y_pred, average = 'weighted'):\n",
    "  predictions = y_pred.squeeze(0).cpu().numpy()\n",
    "  true_labels = y_true.squeeze(0).cpu().numpy()\n",
    "  f1 = f1_score(true_labels, predictions, average=average)\n",
    "  return f1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a73c8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = {}\n",
    "\n",
    "for i in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    f1s[i] = {}\n",
    "    for j in [5,10,125,250,500]:\n",
    "        f1s[i][j] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c495c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.1: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.2: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.3: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.4: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.5: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.6: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.7: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.8: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 0.9: {5: [], 10: [], 125: [], 250: [], 500: []},\n",
       " 1.0: {5: [], 10: [], 125: [], 250: [], 500: []}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500,57547,500):\n",
    "    #print(i, 57547-i)\n",
    "    j = i+500\n",
    "    tlogits, tembeddings, tlabels = logits[:,i:j:], embeddings[:,i:j,:], labels[:,i:j]\n",
    "    for lambda_ in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for k in [5,10,125,250,500]:\n",
    "            predicted_labels_protoype_average = get_logits(tlogits, tembeddings, new_datastore_keys, new_datastore_values, 42, k, lambda_)\n",
    "            f1 = get_f1_score(tlabels, predicted_labels_protoype_average)\n",
    "            f1s[lambda_][k].append(f1)\n",
    "            print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2286b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 5 0.9491600862673334\n",
      "0.0 10 0.9508867567388144\n",
      "0.0 125 0.9607593724390714\n",
      "0.0 250 0.9635460499663281\n",
      "0.0 500 0.9647693098627762\n",
      "0.1 5 0.959416684771326\n",
      "0.1 10 0.9615545317073475\n",
      "0.1 125 0.9660052770217675\n",
      "0.1 250 0.9674801326695979\n",
      "0.1 500 0.9688637035498704\n",
      "0.2 5 0.9668261773295824\n",
      "0.2 10 0.9674801836318679\n",
      "0.2 125 0.9690396063305886\n",
      "0.2 250 0.9697204133280399\n",
      "0.2 500 0.9705573229783027\n",
      "0.3 5 0.97001252181818\n",
      "0.3 10 0.9703821785087027\n",
      "0.3 125 0.970742436402798\n",
      "0.3 250 0.9709743161031822\n",
      "0.3 500 0.9712512074763876\n",
      "0.4 5 0.9716252037931844\n",
      "0.4 10 0.9715447559095843\n",
      "0.4 125 0.9715269120519034\n",
      "0.4 250 0.971545217983545\n",
      "0.4 500 0.9719267706027336\n",
      "0.5 5 0.9721713396593812\n",
      "0.5 10 0.9720976407729347\n",
      "0.5 125 0.9719142234231674\n",
      "0.5 250 0.9720860882415782\n",
      "0.5 500 0.9722174131897752\n",
      "0.6 5 0.972421874401129\n",
      "0.6 10 0.9723379923510994\n",
      "0.6 125 0.9723192273003461\n",
      "0.6 250 0.9722895746743239\n",
      "0.6 500 0.972482064397995\n",
      "0.7 5 0.972438623724556\n",
      "0.7 10 0.9724309581264741\n",
      "0.7 125 0.9723199143673183\n",
      "0.7 250 0.9723956999120841\n",
      "0.7 500 0.9725412585601645\n",
      "0.8 5 0.9725712927802516\n",
      "0.8 10 0.9725637856655281\n",
      "0.8 125 0.9725476349217179\n",
      "0.8 250 0.9725395138793188\n",
      "0.8 500 0.9725705287999521\n",
      "0.9 5 0.9725968575901696\n",
      "0.9 10 0.9726158325195783\n",
      "0.9 125 0.9725471669448263\n",
      "0.9 250 0.9725210198133921\n",
      "0.9 500 0.9725569011199039\n",
      "1.0 5 0.9724189971691566\n",
      "1.0 10 0.9724189971691566\n",
      "1.0 125 0.9724189971691566\n",
      "1.0 250 0.9724189971691566\n",
      "1.0 500 0.9724189971691566\n"
     ]
    }
   ],
   "source": [
    "max_f1 = 0\n",
    "for i in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    for j in [5,10,125,250,500]:\n",
    "        f1s_list = f1s[i][j]\n",
    "        f1s_list_mean = sum(f1s_list) / len(f1s_list)\n",
    "        max_f1 = max(max_f1, f1s_list_mean)\n",
    "        print(i,j,f1s_list_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f7ea211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9724189971691566"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s_list_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
