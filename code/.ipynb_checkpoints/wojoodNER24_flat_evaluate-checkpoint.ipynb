{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZD31r2uf-Ux"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4TETlBEcuG3",
    "outputId": "dfcd0195-63f0-4d9a-a081-679ec76fb0d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-16GB\n",
      "Thu Apr 18 07:33:15 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0              24W / 300W |      2MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    !nvidia-smi\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_YuRDWzcv8g",
    "outputId": "0bcfd10c-3b7f-4ef3-98e6-a7adf7fdac69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: farasapy==0.0.14 in /usr/local/lib/python3.10/dist-packages (0.0.14)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy==0.0.14) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy==0.0.14) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (2024.2.2)\n",
      "Requirement already satisfied: pyarabic==0.6.14 in /usr/local/lib/python3.10/dist-packages (0.6.14)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic==0.6.14) (1.16.0)\n",
      "fatal: destination path 'arabert' already exists and is not an empty directory.\n",
      "Requirement already satisfied: emoji==1.6.1 in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
      "Requirement already satisfied: sentencepiece==0.1.96 in /usr/local/lib/python3.10/dist-packages (0.1.96)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install farasapy==0.0.14\n",
    "!pip install pyarabic==0.6.14\n",
    "!git clone https://github.com/aub-mind/arabert\n",
    "!pip install emoji==1.6.1\n",
    "!pip install sentencepiece==0.1.96\n",
    "!pip install seqeval\n",
    "#!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djzOxAz4x7sV",
    "outputId": "e2074349-23b4-42b2-e582-161788d395be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'WNER_24_sharedtask'...\n",
      "remote: Enumerating objects: 68, done.\u001b[K\n",
      "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
      "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
      "remote: Total 68 (delta 24), reused 63 (delta 19), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (68/68), 26.39 KiB | 13.20 MiB/s, done.\n",
      "Resolving deltas: 100% (24/24), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AhmedAbdel-Aal/WNER_24_sharedtask.git\n",
    "!cp -r WNER_24_sharedtask/code/*.py .\n",
    "!rm -rf WNER_24_sharedtask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z89S1TxOcv_M"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (AutoConfig, AutoModel, AutoModelForSequenceClassification,\n",
    "                          AutoTokenizer, BertTokenizer, Trainer,\n",
    "                          TrainingArguments)\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer\n",
    "from transformers import Trainer , TrainingArguments\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import resample\n",
    "import logging\n",
    "import torch\n",
    "from utils import *\n",
    "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uij3wvOKcwBt",
    "outputId": "7343787c-cbe2-4b52-d87f-45a08be89f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded from path /content/drive/MyDrive/anlp24/WojoodNER_fine_Data/split70.json\n",
      "data loaded from path /content/drive/MyDrive/anlp24/WojoodNER_fine_Data/split10.json\n"
     ]
    }
   ],
   "source": [
    "train_data = load_json('/content/drive/MyDrive/anlp24/WojoodNER_fine_Data/split70.json')\n",
    "dev_data = load_json('/content/drive/MyDrive/anlp24/WojoodNER_fine_Data/split10.json')\n",
    "\n",
    "def normalize_data(items):\n",
    "    normalized_data = []\n",
    "    text_lists = []\n",
    "    label_list = []\n",
    "    for item in items:\n",
    "        sentence_id = item['global_sentence_id']\n",
    "        sentence = []\n",
    "        labels = []\n",
    "        for token_info in item['tokens']:\n",
    "            word = token_info['token']\n",
    "            tv = token_info['tags'][0]\n",
    "            label = tv['value']\n",
    "            sentence.append(word)\n",
    "            labels.append(label)\n",
    "        #sentence = ' '.join(sentence)\n",
    "        #labels = ' '.join(labels)\n",
    "        text_lists.append(sentence)\n",
    "        label_list.append(labels)\n",
    "    return text_lists, label_list\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "text_train, labels_train = normalize_data(train_data)\n",
    "text_dev, labels_dev = normalize_data(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNhtv4vJdqbd"
   },
   "outputs": [],
   "source": [
    "# prompt: load the saved model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2\")\n",
    "model_loaded = AutoModelForTokenClassification.from_pretrained(\"/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2ISKV9kyg7u"
   },
   "outputs": [],
   "source": [
    "label_map = model_loaded.config.label2id\n",
    "inv_label_map = model_loaded.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i6YXb3ZcwEV"
   },
   "outputs": [],
   "source": [
    "from data import NERDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyuCGIq9cwG5"
   },
   "outputs": [],
   "source": [
    "model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "task_name = 'tokenclassification'\n",
    "tokenizer_name = \"/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pIJRVA0cwLV"
   },
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(\n",
    "    texts=text_train,\n",
    "    tags=labels_train,\n",
    "    label_map=label_map,\n",
    "    model_name=model_name,\n",
    "    tokenizer_name=tokenizer_name,\n",
    "    max_length=512,\n",
    "    )\n",
    "\n",
    "dev_dataset = NERDataset(\n",
    "    texts=text_dev,\n",
    "    tags=labels_dev,\n",
    "    label_map=label_map,\n",
    "    model_name=model_name,\n",
    "    tokenizer_name=tokenizer_name,\n",
    "    max_length=512,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9dqRNx89MmH"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  torch.backends.cudnn.deterministic=True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA7mUXDg4dMd"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate_fn function to handle batching of InputFeatures.\n",
    "\n",
    "    Args:\n",
    "    - batch: A list of InputFeatures instances.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with keys 'input_ids', 'attention_mask', 'token_type_ids', 'labels',\n",
    "      where the values are batched tensors.\n",
    "    \"\"\"\n",
    "    # Initialize containers for the various features\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    labels = []\n",
    "    texts = []\n",
    "\n",
    "\n",
    "    for item in batch:\n",
    "        #print(item)\n",
    "        input_ids.append(torch.tensor(item['input_ids']))  # Convert to tensor\n",
    "        attention_masks.append(torch.tensor(item['attention_mask']))  # Convert to tensor\n",
    "        token_type_ids.append(torch.tensor(item['token_type_ids']))  # Convert to tensor\n",
    "        labels.append(torch.tensor(item['labels']))\n",
    "        texts.append(item['text'])\n",
    "\n",
    "    # Convert lists to tensors and stack them\n",
    "    input_ids = torch.stack(input_ids)\n",
    "    attention_masks = torch.stack(attention_masks)\n",
    "    token_type_ids = torch.stack(token_type_ids)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_masks,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'label': labels,\n",
    "        'texts':texts\n",
    "    }\n",
    "\n",
    "# Prepare DataLoader'\n",
    "#batch_size = 16  # Or any batch size that fits your memory\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=5)\n",
    "#test_loader = DataLoader(dev_dataset, batch_size=batch_size,collate_fn=collate_fn, shuffle=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cUuz8yz5KTE"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # Or any batch size that fits your memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=5)\n",
    "test_loader = DataLoader(dev_dataset, batch_size=batch_size,collate_fn=collate_fn, shuffle=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnQhVE5f5LPT"
   },
   "source": [
    "# Infere - Model Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UB-70TMJ5UE1"
   },
   "outputs": [],
   "source": [
    "def align_predictions(predictions, label_ids):\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    label_ids = label_ids.detach().cpu().numpy()\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "\n",
    "    batch_size, seq_len = preds.shape\n",
    "\n",
    "    out_label_list = [[] for _ in range(batch_size)]\n",
    "    preds_list = [[] for _ in range(batch_size)]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            if label_ids[i, j] != torch.nn.CrossEntropyLoss().ignore_index:\n",
    "                out_label_list[i].append(inv_label_map[label_ids[i][j]])\n",
    "                preds_list[i].append(inv_label_map[preds[i][j]])\n",
    "\n",
    "    return preds_list, out_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7TbORiK5T_X",
    "outputId": "4adb28ef-4b95-4556-fab5-b8547b9d4650"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/207 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "100%|██████████| 207/207 [01:03<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "text_tokens = []\n",
    "predicted_tag_1 = []\n",
    "true_tags = []\n",
    "model_loaded.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    batch = {k: v.to(device) if 'texts' not in k else v for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        labels = batch['label']\n",
    "        outputs = model_loaded(input_ids, attention_mask, token_type_ids)\n",
    "        preds, aligned_true_tags = align_predictions(outputs.logits, labels)\n",
    "        for i,j,k in zip(batch['texts'], preds, aligned_true_tags):\n",
    "          text_tokens.append(i)\n",
    "          predicted_tag_1.append(j)\n",
    "          true_tags.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ET0QjQX3HABt",
    "outputId": "a3c5bad9-447b-4be9-9da0-d2471bdc7acd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3304"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_tag_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOiPEhCKGAbB"
   },
   "outputs": [],
   "source": [
    "assert len(predicted_tag_1) == len(true_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ityOlhw670J",
    "outputId": "e460ed1a-fa07-4e9f-a772-fcad314e3caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:         0.9087007683256039\n",
      "acc:        0.9728569690861383\n",
      "precision:  0.8991780821917809\n",
      "recall:     0.9184273121589478\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "print('f1:        ',f1_score(true_tags, predicted_tag_1))\n",
    "print('acc:       ', accuracy_score(true_tags, predicted_tag_1))\n",
    "print('precision: ', precision_score(true_tags, predicted_tag_1))\n",
    "print('recall:    ', recall_score(true_tags, predicted_tag_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsWRl0pZ6jVf"
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmWzawdptmbs"
   },
   "outputs": [],
   "source": [
    "def create_index(embeddings, label_ids):\n",
    "    batch_size, seq_len, _ = embeddings.shape\n",
    "    label_ids = label_ids.detach().cpu().numpy()\n",
    "    embeddings = embeddings.detach().cpu().numpy()\n",
    "\n",
    "    ignored_index = torch.nn.CrossEntropyLoss().ignore_index\n",
    "\n",
    "\n",
    "    valid_mask = label_ids != ignored_index\n",
    "\n",
    "    # Use boolean indexing to filter out the embeddings and logits\n",
    "    filtered_embeddings = embeddings[valid_mask]\n",
    "    filtered_labels = label_ids[valid_mask]\n",
    "\n",
    "    # Map labels using inv_label_map, vectorized operation\n",
    "    out_label_list = [inv_label_map[label.item()] for label in filtered_labels]\n",
    "\n",
    "    assert len(filtered_embeddings) == len(filtered_labels)\n",
    "    return torch.tensor(filtered_embeddings), out_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQnDgI_mtBc4"
   },
   "outputs": [],
   "source": [
    "def create_datastore(model, loader, device):\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in tqdm(loader):\n",
    "        batch = {k: v.to(device) if 'texts' not in k else v for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            token_type_ids = batch['token_type_ids']\n",
    "            labels = batch['label']\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids,output_hidden_states=True)\n",
    "            embeddings = outputs.hidden_states[-1]\n",
    "\n",
    "            in_embeddings, in_labels = create_index(embeddings, labels)\n",
    "            train_embeddings.extend(in_embeddings)\n",
    "            train_labels.extend(in_labels)\n",
    "    return np.vstack(train_embeddings), np.vstack(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hi_JZ23TCPnt",
    "outputId": "8786ddba-bd78-4a71-fc3c-8acac670cb55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1446 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "100%|█████████▉| 1445/1446 [03:54<00:00,  6.14it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "100%|██████████| 1446/1446 [03:55<00:00,  6.14it/s]\n"
     ]
    }
   ],
   "source": [
    "datastore_keys, datastore_values = create_datastore(model_loaded, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_cLUpRqCPrD",
    "outputId": "ed9d76a5-2f61-489d-cf21-abc851afae17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((390900, 768), (390900, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore_keys.shape, datastore_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGyEAsDeifJH"
   },
   "outputs": [],
   "source": [
    "# prompt: save datastore_keys and datastore_values as .npy files\n",
    "\n",
    "import numpy as np\n",
    "np.save('/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2/datastore_keys.npy', datastore_keys)\n",
    "np.save('/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2/datastore_values.npy', datastore_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uK4KqJ2afjKo"
   },
   "outputs": [],
   "source": [
    "# prompt: load datastore_keys and values from .npy files\n",
    "\n",
    "import numpy as np\n",
    "datastore_keys = np.load('/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2/datastore_keys.npy')\n",
    "datastore_values = np.load('/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2/datastore_values.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V30m8BT0zww0",
    "outputId": "37281d2e-4532-40fd-8671-bebea79e592b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([390900])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore_values = datastore_values.reshape(-1)\n",
    "datastore_values_mapped = [label_map[x] for x in datastore_values]\n",
    "datastore_values_mapped = torch.tensor(datastore_values_mapped)\n",
    "datastore_values_mapped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZqNb_1I9vGjP",
    "outputId": "38cd63f1-3f0f-4696-83ee-fd35f01e19a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 390900])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = torch.from_numpy(datastore_keys.transpose(1, 0))\n",
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW-3fuuww-XX"
   },
   "outputs": [],
   "source": [
    "def choose(embeddings, label_ids, logits, inv_label_map):\n",
    "    batch_size, seq_len, _ = embeddings.shape\n",
    "    label_ids = label_ids.detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    embeddings = embeddings.detach().cpu().numpy()\n",
    "\n",
    "    ignored_index = torch.nn.CrossEntropyLoss().ignore_index\n",
    "\n",
    "    valid_mask = label_ids != ignored_index\n",
    "\n",
    "    # Use boolean indexing to filter out the embeddings and logits\n",
    "    filtered_embeddings = embeddings[valid_mask]\n",
    "    filtered_logits = logits[valid_mask]\n",
    "    filtered_labels = label_ids[valid_mask]\n",
    "\n",
    "    # Map labels using inv_label_map, vectorized operation\n",
    "    out_label_list = [inv_label_map[label.item()] for label in filtered_labels]\n",
    "\n",
    "    assert len(filtered_embeddings) == len(filtered_logits)\n",
    "    assert len(filtered_embeddings) == len(filtered_labels)\n",
    "    return torch.tensor(filtered_embeddings), out_label_list, torch.tensor(filtered_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v78R4xctKL-"
   },
   "outputs": [],
   "source": [
    "def postprocess_logits_to_labels(logits, embedding_test, keys, datastore_values_mapped):\n",
    "  #i = 2\n",
    "  batch = embedding_test.shape[0]\n",
    "  num_labels=42\n",
    "  hidden_size = embedding_test.shape[-1]\n",
    "  ##########\n",
    "  embedding_test = embedding_test.view(-1, hidden_size)\n",
    "  ##########\n",
    "  #print(embedding_test.shape)\n",
    "\n",
    "  sim = torch.mm(embedding_test, keys)\n",
    "\n",
    "  #print(sim.shape)\n",
    "\n",
    "  #norm_1 = (keys ** 2).sum(dim=0, keepdim=True).sqrt()\n",
    "  #norm_2 = (embedding_test ** 2).sum(dim=1, keepdim=True).sqrt()\n",
    "\n",
    "  norm_keys = torch.norm(keys, dim=0, keepdim=True)\n",
    "  norm_embeddings = torch.norm(embedding_test, dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "\n",
    "  #scores = (sim / (norm_1 + 1e-10) / (norm_2 + 1e-10)).view(1, embedding_test.shape[0], -1)\n",
    "  scores = sim / (norm_keys * norm_embeddings + 1e-10)\n",
    "  scores = scores.view(1, embedding_test.shape[0], -1)\n",
    "\n",
    "  #print(scores.shape)\n",
    "\n",
    "  topk_scores, topk_idxs = torch.topk(scores, dim=-1, k=8)\n",
    "  #print(topk_idxs[:,i])\n",
    "  #print(topk_scores[:,i])\n",
    "\n",
    "  datastore_size = keys.shape[1]\n",
    "  #print(datastore_size)\n",
    "  knn_labels = datastore_values_mapped.unsqueeze(0)\n",
    "  #print(knn_labels)\n",
    "  knn_labels = knn_labels.view(1, 1, datastore_size).expand(1, batch, datastore_size)\n",
    "  knn_labels = knn_labels.gather(dim=-1, index=topk_idxs)\n",
    "  #print(knn_labels[:,i])\n",
    "\n",
    "  sim_probs = torch.softmax(topk_scores , dim=-1)\n",
    "  #print(sim_probs[:,i])\n",
    "  knn_probabilities = torch.zeros_like(sim_probs[:, :, 0]).unsqueeze(-1).repeat([1,1,num_labels])\n",
    "  knn_probabilities = knn_probabilities.scatter_add(dim=2, index=knn_labels, src=sim_probs)\n",
    "  knn_probabilities = knn_probabilities.squeeze(0)\n",
    "\n",
    "  return knn_probabilities, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yt0e90AXtKPF"
   },
   "outputs": [],
   "source": [
    "def knn_inference(model, device, loader, keys, values_mapped):\n",
    "    text_tokens = []\n",
    "    all_data_logits = []\n",
    "    all_knn_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in tqdm(loader):\n",
    "        batch = {k: v.to(device) if 'texts' not in k else v for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            token_type_ids = batch['token_type_ids']\n",
    "            labels = batch['label']\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids,output_hidden_states=True)\n",
    "\n",
    "            test_embeddings = outputs.hidden_states[-1]\n",
    "            test_logits = outputs.logits\n",
    "            test_labels = labels\n",
    "\n",
    "            aligned_embeddings, aligned_labels, aligned_logits = choose(test_embeddings, test_labels, test_logits, inv_label_map)\n",
    "\n",
    "            knn_logits, logits = postprocess_logits_to_labels(aligned_logits, aligned_embeddings, keys, datastore_values_mapped)\n",
    "\n",
    "            text_tokens.append(batch['texts'])\n",
    "            all_data_logits.append(logits)\n",
    "            all_knn_logits.append(knn_logits)\n",
    "            all_labels.append(aligned_labels)\n",
    "    return text_tokens, all_data_logits, all_knn_logits, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9NFaJV1IXWI",
    "outputId": "19c0434c-7cf4-4cd2-d48e-ac1bf5637780"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/207 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "100%|██████████| 207/207 [04:21<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "text_tokens, all_data_logits, all_knn_logits, all_labels = knn_inference(model_loaded, device, test_loader, keys, datastore_values_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbx3evVJtKR_",
    "outputId": "6e15f11a-155a-4d0a-dcdf-d22cefb8710d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 207, 207, 207)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_tokens), len(all_data_logits), len(all_knn_logits), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZ0IsmBd1rVZ",
    "outputId": "a9afe07c-ad5d-4788-9133-e03d5d08afbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:         0.9086371828642729\n",
      "----------------------------------------\n",
      "f1:         0.9081964941453613\n",
      "----------------------------------------\n",
      "f1:         0.90871311816041\n",
      "----------------------------------------\n",
      "f1:         0.9088390135771682\n",
      "----------------------------------------\n",
      "f1:         0.9090027700831026\n",
      "----------------------------------------\n",
      "f1:         0.9091538568065366\n",
      "----------------------------------------\n",
      "f1:         0.9092672115251419\n",
      "----------------------------------------\n",
      "f1:         0.9092797783933518\n",
      "----------------------------------------\n",
      "f1:         0.9089272110256942\n",
      "----------------------------------------\n",
      "f1:         0.9086881273797162\n",
      "----------------------------------------\n",
      "f1:         0.9084867783469472\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.0\n",
    "\n",
    "for lambda_ in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "  predicted_tag = []\n",
    "  true_tag = []\n",
    "  for i in range(len(all_data_logits)):\n",
    "    data_logtis = all_data_logits[i].squeeze(0)\n",
    "    knn_logits = all_knn_logits[i].squeeze(0)\n",
    "\n",
    "    probabilities = lambda_*data_logtis + (1-lambda_)*knn_logits\n",
    "\n",
    "    argmax_labels = torch.argmax(probabilities, -1, keepdim=False)\n",
    "    argmax_labels = argmax_labels.detach().cpu().numpy()\n",
    "\n",
    "    predicted_tag.append([inv_label_map[label] for label in argmax_labels])\n",
    "    true_tag.append(all_labels[i])\n",
    "\n",
    "  print('f1:        ',f1_score(true_tag, predicted_tag))\n",
    "  #print('acc:       ', accuracy_score(true_tag, predicted_tag))\n",
    "  #print('precision: ', precision_score(true_tag, predicted_tag))\n",
    "  #print('recall:    ', recall_score(true_tag, predicted_tag))\n",
    "  print('----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WQ-vTNU1rjT"
   },
   "outputs": [],
   "source": [
    "def knn_inference_2(model, device, loader, keys, values_mapped):\n",
    "    predicted_tags = []\n",
    "    true_tags = []\n",
    "    all_knn_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in tqdm(loader):\n",
    "        batch = {k: v.to(device) if 'texts' not in k else v for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            token_type_ids = batch['token_type_ids']\n",
    "            labels = batch['label']\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids,output_hidden_states=True)\n",
    "\n",
    "            test_embeddings = outputs.hidden_states[-1]\n",
    "            test_logits = outputs.logits\n",
    "            test_labels = labels\n",
    "\n",
    "            aligned_embeddings, aligned_labels, aligned_logits = choose(test_embeddings, test_labels, test_logits, inv_label_map)\n",
    "\n",
    "            knn_logits, logits = postprocess_logits_to_labels(aligned_logits, aligned_embeddings, keys, datastore_values_mapped)\n",
    "            print(knn_logits.shape)\n",
    "            predicted_tag = np.argmax(knn_logits.detach().cpu().numpy(), axis=-1, keepdims=False)\n",
    "            print(predicted_tag.shape)\n",
    "\n",
    "            predicted_tags.append([inv_label_map[label] for label in predicted_tag])\n",
    "            #predicted_tags.append(predicted_tag)\n",
    "            true_tags.append(aligned_labels)\n",
    "            break\n",
    "\n",
    "    return predicted_tags, true_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ay2G9s9m1rl6",
    "outputId": "50daf0a9-123f-4d65-b509-52e29557abed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/207 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([660, 42])\n",
      "(660,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_tags, true_tags = knn_inference_2(model_loaded, device, test_loader, keys, datastore_values_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cz4ZlHDbO05_",
    "outputId": "858379e8-3351-4cc3-9a37-5bfb1e18ef92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_tags), len(true_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZMqcvjSJNS37",
    "outputId": "4336f9be-267a-4e92-f462-97a93a4fd584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OCC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CURR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERS', 'O', 'B-PERS', 'I-PERS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'B-LANGUAGE', 'O', 'O', 'O', 'B-LANGUAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LANGUAGE', 'B-LANGUAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERS', 'O', 'B-PERS', 'I-PERS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LANGUAGE', 'O', 'O', 'O', 'O', 'B-LANGUAGE', 'I-LANGUAGE', 'O', 'O', 'B-LANGUAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LANGUAGE', 'I-LANGUAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(predicted_tags, true_tags):\n",
    "  print(i)\n",
    "  print(j)\n",
    "  print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzSBECrS1row",
    "outputId": "36a456d3-0d5d-489e-c173-95c21fa0a1f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5652173913043478"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true_tags, predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RW8AubBB1rrc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGOj1oMA1ruO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSqVeCfR1rxF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQ_NgGZ_1rzw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "funD6s6R1r2V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIEgv9JZ1r49"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eU-u0II81r7m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2j3YLEcCtBuk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhuE6sv2fOh8"
   },
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iyQKIhK_dpqW",
    "outputId": "60682e42-d1b4-47a4-eabb-35b48d48fb99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqIWYEi8d5jr"
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgwi_is76nqU"
   },
   "outputs": [],
   "source": [
    "def _normalizer(x, epsilon=1e-10) -> np.ndarray:\n",
    "        return x / (np.linalg.norm(x, axis=-1, keepdims=True) + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqDUbQvq6E30"
   },
   "outputs": [],
   "source": [
    "def create_index(embeddings, label_ids):\n",
    "    batch_size, seq_len, _ = embeddings.shape\n",
    "    label_ids = label_ids.detach().cpu().numpy()\n",
    "    embeddings = embeddings.detach().cpu().numpy()\n",
    "\n",
    "    out_label_list = []\n",
    "    in_embeddings = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            if label_ids[i, j] != torch.nn.CrossEntropyLoss().ignore_index:\n",
    "                out_label_list.append(inv_label_map[label_ids[i][j]])\n",
    "                in_embeddings.append(embeddings[i][j])\n",
    "    return in_embeddings, out_label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8G3cD8meWWx"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # Or any batch size that fits your memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C36aDrIz4dSc",
    "outputId": "318791b4-ea69-4039-eaa9-7599a8d6e030"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1446/1446 [07:12<00:00,  3.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = []\n",
    "train_labels = []\n",
    "\n",
    "model_loaded.eval()\n",
    "for batch in tqdm(train_loader):\n",
    "    batch = {k: v.to(device) if 'texts' not in k else v for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        labels = batch['label']\n",
    "        outputs = model_loaded(input_ids, attention_mask, token_type_ids,output_hidden_states=True)\n",
    "        embeddings = outputs.hidden_states[-1]\n",
    "\n",
    "        in_embeddings, in_labels = create_index(embeddings, labels)\n",
    "        train_embeddings.extend(in_embeddings)\n",
    "        train_labels.extend(in_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1G6LNElEBKiN",
    "outputId": "33eb9881-c7b3-49e5-bf0f-da3291e16907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390900, 390900)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_embeddings), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ioh4DyhgbnC",
    "outputId": "08ba75c1-4309-4444-d5a3-575226456855"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390900, 768)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array = np.vstack(train_embeddings)\n",
    "features_array = _normalizer(features_array)\n",
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqTKUenze3lx"
   },
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(features_array.shape[1])\n",
    "index.add(features_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_hYnWz3fAaN"
   },
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2/my_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hX0C6rtZkYEY"
   },
   "outputs": [],
   "source": [
    "np.save('/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2/index_labels.npy', train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nOj4Uv4fQ_b"
   },
   "source": [
    "## Load index and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g18REDI1fAds"
   },
   "outputs": [],
   "source": [
    "loaded_index = faiss.read_index(\"/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2/my_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LB8DJy52fAg9",
    "outputId": "1f5ccff5-f651-40a3-d6ab-1997f03c6c92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390900, 768)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_index.ntotal, loaded_index.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KnDxtYs7kmop",
    "outputId": "9a47b5d5-1381-4338-830a-09ebea56d6ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([390900])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_labels = np.load('/content/drive/MyDrive/anlp24/nerflat-arabertv02-e3/output_dir2/index_labels.npy')\n",
    "index_labels = [label_map[label] for label in index_labels]\n",
    "index_labels = torch.tensor(index_labels)\n",
    "index_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqMyZZX-hQ25"
   },
   "outputs": [],
   "source": [
    "def choose(embeddings, label_ids, logits):\n",
    "    batch_size, seq_len, _ = embeddings.shape\n",
    "    label_ids = label_ids.detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    embeddings = embeddings.detach().cpu().numpy()\n",
    "\n",
    "    out_label_list = []\n",
    "    in_embeddings = []\n",
    "    in_logits = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            if label_ids[i, j] != torch.nn.CrossEntropyLoss().ignore_index:\n",
    "                out_label_list.append(inv_label_map[label_ids[i][j]])\n",
    "                in_embeddings.append(embeddings[i][j])\n",
    "                in_logits.append(logits[i][j])\n",
    "    return in_embeddings, out_label_list, in_logits\n",
    "\n",
    "def get_knn_logits(faiss_index, embeddings, index_labels, K=512, num_labels=42):\n",
    "  embeddings = embeddings.reshape(embeddings.shape[0],-1)\n",
    "\n",
    "  embeddings = embeddings.numpy()\n",
    "  embeddings = _normalizer(embeddings)\n",
    "  out = faiss_index.search(embeddings,k=K)\n",
    "  dist, idx = out\n",
    "  #sim = -1 * dist\n",
    "  #sim = 1/(1+dist)\n",
    "  sim = np.exp(-dist)\n",
    "  #np.exp(-distances**2 / (2 * sigma**2)) where sigma is 1.0\n",
    "\n",
    "\n",
    "  sim_probs = torch.softmax(torch.from_numpy(sim), dim=-1)\n",
    "  sim_probs = sim_probs.unsqueeze(0)\n",
    "\n",
    "  knn_probabilities = torch.zeros_like(sim_probs[:, :, 0]).unsqueeze(-1).repeat([1,1,num_labels])\n",
    "\n",
    "  index = index_labels[idx].unsqueeze(0)\n",
    "\n",
    "  knn_probabilities = knn_probabilities.scatter_add(dim=2, index=index, src=sim_probs)\n",
    "  return knn_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TN0x9_WP5rio"
   },
   "outputs": [],
   "source": [
    "text_tokens = []\n",
    "all_data_logits = []\n",
    "all_knn_logits = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8F4Em6EfAkF",
    "outputId": "029ddcca-b120-4bfb-ca31-585a7220410d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/207 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "100%|██████████| 207/207 [12:09<00:00,  3.52s/it]\n"
     ]
    }
   ],
   "source": [
    "model_loaded.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    batch = {k: v.to(device) if 'texts' not in k else v for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        input_ids, attention_mask, token_type_ids = batch['input_ids'], batch['attention_mask'], batch['token_type_ids']\n",
    "        labels = batch['label']\n",
    "\n",
    "        outputs = model_loaded(input_ids, attention_mask, token_type_ids,output_hidden_states=True)\n",
    "\n",
    "        embeddings, logits = outputs.hidden_states[-1], outputs.logits\n",
    "\n",
    "        aligned_embeddings, aligned_labels, aligned_logits = choose(embeddings, labels, logits)\n",
    "\n",
    "        aligned_logits = torch.tensor(aligned_logits).unsqueeze(0)\n",
    "        aligned_embeddings = torch.tensor(aligned_embeddings)\n",
    "\n",
    "        knn_logits= get_knn_logits(loaded_index, aligned_embeddings,index_labels)\n",
    "\n",
    "        assert aligned_logits.shape == knn_logits.shape\n",
    "\n",
    "\n",
    "        for i,j,k,l in zip(batch['texts'], aligned_logits, knn_logits, aligned_labels):\n",
    "          text_tokens.append(i)\n",
    "          all_data_logits.append(j)\n",
    "          all_knn_logits.append(k)\n",
    "          all_labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EeZwIeVfAmz",
    "outputId": "0c5d0ea5-7105-429c-a553-9f4072fadf2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 207, 207, 207)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data_logits), len(all_knn_logits), len(text_tokens), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEZomq6jy0E9",
    "outputId": "23db3362-75b9-4b02-e2cb-c3fa7be6341e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:         0.9085742011506204\n",
      "----------------------------------------\n",
      "f1:         0.9082594235033259\n",
      "----------------------------------------\n",
      "f1:         0.90871311816041\n",
      "----------------------------------------\n",
      "f1:         0.9088390135771682\n",
      "----------------------------------------\n",
      "f1:         0.9090027700831026\n",
      "----------------------------------------\n",
      "f1:         0.9091538568065366\n",
      "----------------------------------------\n",
      "f1:         0.9092672115251419\n",
      "----------------------------------------\n",
      "f1:         0.9092797783933518\n",
      "----------------------------------------\n",
      "f1:         0.9089272110256942\n",
      "----------------------------------------\n",
      "f1:         0.9086881273797162\n",
      "----------------------------------------\n",
      "f1:         0.9084867783469472\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.0\n",
    "\n",
    "for lambda_ in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "  predicted_tag = []\n",
    "  true_tag = []\n",
    "  for i in range(len(all_data_logits)):\n",
    "    data_logtis = all_data_logits[i].squeeze(0)\n",
    "    knn_logits = all_knn_logits[i].squeeze(0)\n",
    "\n",
    "    probabilities = lambda_*data_logtis + (1-lambda_)*knn_logits\n",
    "\n",
    "    argmax_labels = torch.argmax(probabilities, -1, keepdim=False)\n",
    "    argmax_labels = argmax_labels.detach().cpu().numpy()\n",
    "\n",
    "    predicted_tag.append([inv_label_map[label] for label in argmax_labels])\n",
    "    true_tag.append(all_labels[i])\n",
    "\n",
    "  print('f1:        ',f1_score(true_tag, predicted_tag))\n",
    "  #print('acc:       ', accuracy_score(true_tag, predicted_tag))\n",
    "  #print('precision: ', precision_score(true_tag, predicted_tag))\n",
    "  #print('recall:    ', recall_score(true_tag, predicted_tag))\n",
    "  print('----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFyV9v6yIm7d",
    "outputId": "4c613523-d3fc-47e0-f114-e99d68cdb003"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 207)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_tag), len(true_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjnJvxu41nAd",
    "outputId": "19353cc2-a5c4-44b4-c873-2df3ebe20805"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9084867783469472"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tag = [[item for sublist in predicted_tag for item in sublist]]\n",
    "true_tag = [[item for sublist in true_tag for item in sublist]]\n",
    "\n",
    "f1_score(true_tag, predicted_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYlO0ErXIlmx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmCLuNp5Ilp0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBPbS_aTIlsp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qfapipKIlvy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxBqwpjOIlya"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpOcojwgGTl4",
    "outputId": "07dab940-0b10-4a89-d493-3717b4110956"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67MzMHFK1nFO"
   },
   "outputs": [],
   "source": [
    "predicted_tag_x = [item for sublist in predicted_tag_1 for item in sublist]\n",
    "predicted_tag_y = [item for sublist in predicted_tag for item in sublist]\n",
    "text_tokens_xy = [item for sublist in text_tokens for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6Sra-nA1nC2",
    "outputId": "9e98357a-0e7f-4820-cf35-a8a368914721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57547, 57547, 57555)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_tag_x), len(predicted_tag_y), len(text_tokens_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXQadE4F1nHf"
   },
   "outputs": [],
   "source": [
    "for i in range(len(predicted_tag_1)):\n",
    "        if predicted_tag_x[i] != predicted_tag_y[i]:\n",
    "            print(\"Difference found:\")\n",
    "            print(\"Predicted tag 1:\", predicted_tag_x[i])\n",
    "            print(\"Predicted tag 2:\", predicted_tag_y[i])\n",
    "            print(\"Text token:\", text_tokens_xy[i])\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "24roaJFGG7fg",
    "outputId": "71da5642-f1c9-4e0d-fe98-49a9bcabf6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "O O\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-GPE B-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "B-GPE B-GPE\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "B-LOC B-LOC\n",
      "I-LOC I-LOC\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-LOC B-LOC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-LOC B-LOC\n",
      "I-LOC I-LOC\n",
      "I-LOC I-LOC\n",
      "I-LOC I-LOC\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-LOC B-LOC\n",
      "I-LOC I-LOC\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "I-ORDINAL I-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "I-ORDINAL I-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "I-ORDINAL I-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "B-GPE B-GPE\n",
      "B-GPE B-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "B-CARDINAL B-CARDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-CARDINAL B-CARDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "B-CARDINAL B-CARDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-MONEY B-MONEY\n",
      "I-MONEY I-MONEY\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERCENT B-PERCENT\n",
      "I-PERCENT I-PERCENT\n",
      "I-PERCENT I-PERCENT\n",
      "I-PERCENT I-PERCENT\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERCENT B-PERCENT\n",
      "I-PERCENT I-PERCENT\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-CARDINAL B-CARDINAL\n",
      "O O\n",
      "B-CARDINAL B-CARDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "B-PERS B-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "B-PERS B-PERS\n",
      "B-TIME B-TIME\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "I-OCC I-OCC\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "B-PERS B-PERS\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "I-OCC I-OCC\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "I-NORP I-NORP\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "B-CARDINAL B-CARDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-LOC B-LOC\n",
      "I-LOC I-LOC\n",
      "I-LOC I-LOC\n",
      "B-LOC B-LOC\n",
      "I-LOC I-LOC\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "B-OCC B-OCC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-OCC B-OCC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-CARDINAL B-CARDINAL\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-EVENT B-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "I-EVENT I-EVENT\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "I-GPE I-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "B-ORDINAL B-ORDINAL\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "B-NORP B-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "I-NORP I-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-NORP B-NORP\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "B-DATE B-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "I-DATE I-DATE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-GPE B-GPE\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "B-OCC B-OCC\n",
      "B-PERS B-PERS\n",
      "I-PERS I-PERS\n",
      "B-OCC B-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "I-OCC I-OCC\n",
      "O O\n",
      "O O\n",
      "B-FAC B-FAC\n",
      "I-FAC I-FAC\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "I-ORG I-ORG\n",
      "O O\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-283-1279231b8440>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_tag_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_tag_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,j in zip(predicted_tag_x, predicted_tag_y):\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiU8fRkCG7ia"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErFeJ0rFG7kr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9K_fJPaKG7pb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvE6qQxJG7sO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnEIup-qG7u1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88wrNhvwG7xT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rx7iCuwG7z0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwPNAejc1nJn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAK23vCUrGXX"
   },
   "outputs": [],
   "source": [
    "lambda_ = 0.2\n",
    "probabilities = lambda_*data_logtis + (1-lambda_)*knn_logits\n",
    "argmax_labels = torch.argmax(probabilities, -1, keepdim=False)\n",
    "argmax_labels = argmax_labels.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiKaI7wUsJo2"
   },
   "outputs": [],
   "source": [
    "predicted_tag = [inv_label_map[label] for label in argmax_labels]\n",
    "# prompt: flatten the true_tag list\n",
    "true_tag_flat = [item for sublist in true_tags for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnBIrbl3fAw_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-N1RifnfA0v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtoKkBoJsssa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKVl-scGssux"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VY4b_gIOssxR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34LQXAMNsszp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37unGVX_ss16"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WOnFKRJss4Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4tPA5pYss62"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xafr8EsSss87"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i55tvWEwss_J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1foIwfMstDh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F3p7iWXfA3d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
